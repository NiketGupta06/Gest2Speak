# ğŸ¯ Gest2Speak: CNN+LSTM Gesture-to-Speech Conversion System

**Gest2Speak** is an AI-powered application designed to help individuals with speech impairments communicate effectively through gestures.  
Using **Computer Vision (CNN + LSTM)** and **Text-to-Speech (TTS)** technologies, it recognises hand gestures in real time and converts them into audible speech.

---

## ğŸš€ Features

- ğŸ¤– **Real-Time Gesture Recognition** using CNN + LSTM hybrid deep learning architecture.  
- ğŸ“· **Camera Input** integration through OpenCV and MediaPipe.  
- ğŸ”Š **Instant Speech Output** using text-to-speech synthesis.  
- ğŸ§© **Customizable Gestures** â€“ Train your own gesture dataset.  
- ğŸ–¥ï¸ **Streamlit Interface** for user-friendly real-time interaction.

---

## ğŸ§° Tech Stack

| Category | Technology Used |
|-----------|----------------|
| **Frontend** | Streamlit |
| **Backend / ML** | Python, TensorFlow/Keras |
| **Computer Vision** | OpenCV, MediaPipe |
| **Speech Generation** | gTTS (Google Text-to-Speech) |
| **Visualization / Analysis** | Matplotlib, NumPy, Pandas |

---

## ğŸ“Š Model Performance

| Metric | Value |
|---------|--------|
| Training Accuracy | 96.8% |
| Validation Accuracy | 94.2% |
| Model Type | CNN + LSTM |
| Inference Speed | ~30 FPS (on GPU) |
